{"name":"Sci-analysis","tagline":"A light weight python data analysis and data exploration tool","body":"# sci-analysis\r\nA light weight python data exploration and analysis tool by Chris Morrow\r\n\r\n## Current Version:\r\n1.2 --- Released May 26, 2015\r\n\r\n### What is sci_analysis?\r\nSci_analysis is a python module for performing rapid statistical data analysis. It provides a graphical representation of the supplied data as well as the statistical analysis. Sci_analysis is smart enough to determine the correct analysis and tests to perform based on the shape of the data you provide, as well as whether the data is normally distributed.\r\n\r\nCurrently, sci_analysis can only be used for analyzing numeric data. Categorical data analysis is planned for a future version. The three types of analysis that can be performed are histograms of single vectors, correlation between two vectors and one-way ANOVA.\r\n\r\n### Getting started with sci_analysis\r\nBefore using sci_analysis, be sure the following three packages are installed:\r\n\r\n* numpy\r\n* scipy\r\n* matplotlib\r\n\t\r\nSci_analysis is also compatible with pandas and works best in the iPython Notebook.\r\n\r\nFirst, download to your PC or clone the repo at: \r\nhttps://github.com/cmmorrow/sci-analysis\r\n\r\nNext, add the sci_analysis directory to your project with:\r\n\r\n```python\r\nsys.path.extend(['<path to directory>/sci_analysis'])\r\nimport scianalysis as a\r\nimport numpy as np\r\n```\r\n\r\nThis will tell python were to find sci_analysis and import it to your project as the object `a`. \r\n\r\nIf you are using the iPython Notebook, you will also want to use the following code instead to enable inline plots:\r\n\r\n```python\r\n%matplotlib inline\r\nimport matplotlib\r\nsys.path.extend(['<path to directory>/sci_analysis'])\r\nimport scianalysis as a\r\nimport numpy as np\r\n```\r\n\r\nNow, sci_analysis should be ready to use. Try the following code:\r\n\r\n```python\r\na.analyze(np.random.randn(100))\r\n```\r\n\r\nA histogram and box plot of the data should appear, as well as printed output similar to that below:\r\n\r\n```\r\nStatistics\r\n--------\r\nCount = 100\r\nMean = -0.0346394170379\r\nStandard Deviation = 1.00138009977\r\nSkewness = 0.246797356486\r\nKurtosis = 0.0301715149203\r\nMax = 2.98521191579\r\n75% = 0.618195797909\r\n50% = -0.1045351866\r\n25% = -0.760766375821\r\nMin = -2.43834596493\r\nIQR = 1.37896217373\r\nRange = 5.42355788072\r\n\r\nShapiro-Wilk test for normality\r\n--------\r\nW value = 0.9944\r\np value = 0.9581\r\nH0: Data is normally distributed\r\n```\r\n\r\nYou should probably note that numpy was only imported for the purpose of the above example. Sci_analysis uses numpy internally, so it isn't necessary to import it unless you want to explicitly use it. Sci_analysis can work with regular python sequences as in the following:\r\n\r\n```python\r\nIn[6]: a.clean([6, 9, 12, 15])\r\nOut[6]: array([ 6,  9, 12, 15])\r\n\r\nIn[7]: a.clean((4, 8, 12, 16, 20))\r\nOut[7]: array([ 4,  8, 12, 16, 20])\r\n```\r\n\r\nSci_analysis is also compatible with the pandas Series object. To use pandas with sci_analysis, be sure to import it to your project with:\r\n\r\n```python\r\nimport pandas as pd\r\n```\r\n\r\nThe sci_analysis helper functions can accept a pandas Series object and return a Series as in the example below:\r\n\r\n```python\r\nIn[9]: a.clean(pd.Series([6, 9, 12, 15]))\r\nOut[9]: \r\n0     6\r\n1     9\r\n2    12\r\n3    15\r\ndtype: int64\r\n```\r\n\r\n### How do I use sci_analysis?\r\n\r\nThe easiest and fastest way to use sci_analysis is to call it's `analyze` function. Here's the signature for the `analyze` function:\r\n\r\n```python\r\ndef analyze(xdata, ydata=[], groups=[], name='', xname='', yname='y', alpha=0.05, categories='Categories'):\r\n```\r\n\r\n`analyze` will detect the desired type of data analysis to perform based on whether the `ydata` argument is supplied, and whether the `xdata` argument is a two-dimensional array-like object. \r\n\r\nThe `xdata` and `ydata` arguments can accept most python iterable objects, with the exception of strings. For example, `xdata` will accept a python list or tuple, a numpy ndarray, or a pandas Series. Internally, lists and tuples are converted to ndarrays and Series objects are manipulated using the ndarray methods.\r\n\r\nIf only the `xdata` argument is passed and it is a one-dimensional vector, the analysis performed will be a histogram of the vector with basic statistics and Shapiro-Wilk normality test. This is useful for visualizing the distribution of the vector.\r\n\r\nIf `xdata` and `ydata` are supplied and are both one-dimensional vectors, the correlation between the two vectors will be graphed and calculated. If there are non-numeric or missing values in either vector, they will be ignored. Only values that are numeric in each vector, at the same index will be included in the correlation. For example, the two following vectors will yield:\r\n\r\n```python\r\nIn[24]: example1 = numpy.array([1.0, 2.0, float('nan'), 4.0, float('nan'), 6.0])\r\nIn[25]: example2 = numpy.array([10.0, 20.0, float('nan'), 40.0, 50.0, 60.0])\r\nIn[26]: a.dropnan_intersect(example1, example2)\r\n\r\nOut[26]: (array([ 1.,  2.,  4.,  6.]), array([ 10.,  20.,  40.,  60.]))\r\n```\r\n\r\nThe `dropnan_intersect` function performs what the name implies --- any values that are not-a-number in either vector at the same index will be dropped from the output tuple. It's also important to note that both vector lengths must be equal.\r\n\r\nIf `xdata` is a sequence of vectors, summary statistics will be reported for each vector. If the concatenation of each vector is normally distributed and they all have equal variance, a one-way ANOVA is performed. If the data is not normally distributed or the vectors do not have equal variance, a non-parametric Kruskal-Wallis test will be performed instead of a one-way ANOVA.\r\n\r\nIt is important to note that the vectors should be independent from one another --- that is to say, there should not be values in one vector that are derived from or some how related to a value in another vector. These dependencies can lead to weird and often unpredictable results. For example, a proper use case would be if you had a vector with measurement data and another vector (or vectors) that represent a grouping applied to the measurement data. In this case, each group should be represented by it's own vector, which are then all wrapped in a sequence. the `analyze` function accepts a `groups` argument as a list of strings of grouping names. The order of the group names should match the order of the vectors passed to `xdata`. For example:\r\n\r\n```python\r\nIn[10]: group_a = np.random.randn(6)\r\nIn[11]: group_b = np.random.randn(7)\r\nIn[12]: group_c = np.random.randn(5)\r\nIn[13]: group_d = np.random.randn(8)\r\nIn[14]: names = [\"group_a\", \"group_b\", \"group_c\", \"group_d\"]\r\nIn[17]: data = [group_a, group_b, group_c, group_d]\r\nIn[18]: a.analyze(data, groups=names)\r\nCount     Mean      Std.      Max       50%       Min       Group\r\n----------------------------------------------------------------------\r\n6         0.280     1.008     1.489     0.458     -1.555    group_a   \r\n7         0.131     1.596     1.980     0.678     -2.058    group_b   \r\n5         -0.300    0.932     1.061     -0.457    -1.428    group_c   \r\n8         0.246     0.944     1.964     0.369     -1.284    group_d   \r\n\r\nBartlett Test\r\n--------\r\nT value = 2.3708\r\np value = 0.4991\r\nH0: Variances are equal\r\n\r\nANOVA\r\n--------\r\nf value = 0.2832\r\np value = 0.8369\r\nH0: Group means are matched\r\n```\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}